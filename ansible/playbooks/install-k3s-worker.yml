---
- name: Install k3s worker node on Raspberry Pi
  hosts: raspberry_pi
  become: true
  vars:
    k3s_version: "" # Empty for latest, or specify like "v1.28.5+k3s1"
    k3s_token: "" # Required - node token from control plane
    k3s_server_url: "https://eldertree:6443" # Control plane URL
    k3s_install_k9s: false # k9s not needed on worker nodes

  tasks:
    # =========================================================================
    # Check k3s installation status
    # =========================================================================
    - name: Check if k3s is already installed
      command: which k3s
      register: k3s_check
      changed_when: false
      failed_when: false

    - name: Check if k3s service is running
      systemd:
        name: k3s-agent
      register: k3s_service_status
      changed_when: false
      failed_when: false
      when: k3s_check.rc == 0

    - name: Set fact for k3s already installed
      set_fact:
        k3s_already_installed: "{{ k3s_check.rc == 0 and k3s_service_status.status.ActiveState == 'active' }}"
      when: k3s_check.rc == 0
      changed_when: false

    - name: Set fact for k3s already installed (when not found)
      set_fact:
        k3s_already_installed: false
      when: k3s_check.rc != 0
      changed_when: false

    - name: Fail if k3s token is not provided
      fail:
        msg: "k3s_token is required. Get it from the control plane: cat /var/lib/rancher/k3s/server/node-token"
      when: k3s_token == "" and not (k3s_already_installed | default(false))

    # =========================================================================
    # System Prerequisites - Cgroup Configuration
    # =========================================================================
    - name: Detect boot device (SD or NVMe)
      shell: |
        if [ -b /dev/mmcblk0 ]; then
          echo "sd"
        elif [ -b /dev/nvme0n1 ]; then
          echo "nvme"
        else
          echo "unknown"
        fi
      register: boot_device
      changed_when: false

    - name: Set cmdline.txt path based on boot device
      set_fact:
        cmdline_file: "{{ '/boot/firmware/cmdline.txt' if boot_device.stdout == 'sd' else '/boot/firmware/cmdline.txt' }}"
      changed_when: false

    - name: Check if cgroup setting exists in running kernel
      shell: cat /proc/cmdline | grep -q 'systemd.unified_cgroup_hierarchy=0' && echo 'yes' || echo 'no'
      register: cgroup_running_check
      changed_when: false
      failed_when: false

    - name: Backup and update cmdline.txt with cgroup setting (safely)
      shell: |
        set -e
        CMDLINE_FILE="{{ cmdline_file }}"
        
        # Ensure file exists
        if [ ! -f "$CMDLINE_FILE" ]; then
          echo "ERROR: $CMDLINE_FILE does not exist!"
          exit 1
        fi
        
        # Backup current file
        BACKUP_FILE="${CMDLINE_FILE}.bak.ansible-$(date +%s)"
        cp "$CMDLINE_FILE" "$BACKUP_FILE"
        
        # Read current kernel cmdline as source of truth
        KERNEL_CMDLINE=$(cat /proc/cmdline)
        
        # Validate root= parameter exists in kernel cmdline
        if ! echo "$KERNEL_CMDLINE" | grep -q "root="; then
          echo "ERROR: root= parameter missing in kernel cmdline! Cannot proceed safely."
          exit 1
        fi
        
        # Check if cgroup setting already exists in kernel cmdline
        if echo "$KERNEL_CMDLINE" | grep -q "systemd.unified_cgroup_hierarchy=0"; then
          echo "Cgroup setting already present in kernel, no changes needed to file"
          # Ensure the file matches the kernel if it's different
          if ! cmp -s "$CMDLINE_FILE" <(echo "$KERNEL_CMDLINE"); then
            echo "$KERNEL_CMDLINE" > "$CMDLINE_FILE"
            echo "Updated cmdline.txt to match kernel cmdline"
            exit 0 # Indicate change
          fi
          exit 0 # No change needed
        fi
        
        # Add cgroup setting to kernel cmdline (preserve all existing parameters)
        NEW_CMDLINE="${KERNEL_CMDLINE} systemd.unified_cgroup_hierarchy=0"
        
        # Clean up extra spaces
        NEW_CMDLINE=$(echo "$NEW_CMDLINE" | sed 's/  */ /g' | sed 's/^ //' | sed 's/ $//')
        
        # Validate root= parameter still exists
        if ! echo "$NEW_CMDLINE" | grep -q "root="; then
          echo "ERROR: root= parameter would be lost! Restoring from backup..."
          cp "$BACKUP_FILE" "$CMDLINE_FILE"
          exit 1
        fi
        
        # Write new cmdline to file
        echo "$NEW_CMDLINE" > "$CMDLINE_FILE"
        
        # Final validation
        if ! grep -q "root=" "$CMDLINE_FILE"; then
          echo "ERROR: root= parameter missing after write! Restoring from backup..."
          cp "$BACKUP_FILE" "$CMDLINE_FILE"
          exit 1
        fi
        
        echo "SUCCESS: cmdline.txt updated safely"
      register: cmdline_updated
      changed_when: cmdline_updated.rc == 0 and 'SUCCESS' in cmdline_updated.stdout
      failed_when: cmdline_updated.rc != 0
      when: cgroup_running_check.stdout | default('no') == 'no'

    - name: Set fact for reboot needed
      set_fact:
        reboot_needed: "{{ (cmdline_updated.changed | default(false)) or (cgroup_running_check.stdout | default('no') == 'no') }}"
      changed_when: false

    - name: Reboot if cmdline.txt was updated or cgroup not active
      reboot:
        msg: "Rebooting to apply cgroup configuration"
        reboot_timeout: 300
      when: reboot_needed | default(false)

    - name: Wait for system to come back online after reboot
      wait_for_connection:
        timeout: 300
      when: reboot_needed | default(false)

    - name: Verify connectivity after reboot
      block:
        - name: Test SSH connectivity
          command: echo "connectivity_test"
          register: connectivity_test
          changed_when: false

        - name: Test network connectivity
          shell: ping -c 1 -W 2 8.8.8.8 >/dev/null 2>&1 && echo "ok" || echo "fail"
          register: network_test
          changed_when: false
          failed_when: false

        - name: Fail if connectivity lost after reboot
          fail:
            msg: "CRITICAL: Connectivity lost after reboot! Network test: {{ network_test.stdout }}. Check network configuration and SSH access."
          when: network_test.stdout == "fail"
      when: reboot_needed | default(false)

    - name: Verify cgroup setting is active after reboot
      shell: cat /proc/cmdline | grep -q 'systemd.unified_cgroup_hierarchy=0' && echo 'yes' || echo 'no'
      register: cgroup_verify
      changed_when: false
      failed_when: false
      when: reboot_needed | default(false)

    - name: Verify cgroup setting is active (final check)
      shell: cat /proc/cmdline | grep -q 'systemd.unified_cgroup_hierarchy=0' && echo 'yes' || echo 'no'
      register: cgroup_final_check
      changed_when: false
      failed_when: false

    - name: Fail if cgroup setting is not active after reboot
      fail:
        msg: "Cgroup setting systemd.unified_cgroup_hierarchy=0 is not active in kernel after reboot. Check /boot/firmware/cmdline.txt and ensure the setting is present."
      when: reboot_needed | default(false) and cgroup_verify.stdout | default('no') == 'no'

    - name: Fail if cgroup setting is not active (general check)
      fail:
        msg: "Cgroup setting systemd.unified_cgroup_hierarchy=0 is not active in kernel. A reboot may be required."
      when: not reboot_needed | default(false) and cgroup_final_check.stdout | default('no') == 'no'

    # =========================================================================
    # Install prerequisites
    # =========================================================================
    - name: Install prerequisites
      apt:
        name:
          - curl
          - iptables
        state: present
        update_cache: true
      when: not (k3s_already_installed | default(false))

    # =========================================================================
    # Install k3s worker
    # =========================================================================
    - name: Install k3s worker
      shell: |
        set -e
        export INSTALL_K3S_VERSION="{{ k3s_version }}"
        export K3S_TOKEN="{{ k3s_token }}"
        export K3S_URL="{{ k3s_server_url }}"
        curl -sfL https://get.k3s.io | sh -
      args:
        creates: /usr/local/bin/k3s
      register: k3s_install
      when: not (k3s_already_installed | default(false))

    # =========================================================================
    # Ensure k3s-agent service is running
    # =========================================================================
    - name: Check k3s-agent service status before starting
      systemd:
        name: k3s-agent
      register: k3s_service_status_before
      changed_when: false
      when: k3s_check.rc == 0

    - name: Ensure k3s-agent service is started
      systemd:
        name: k3s-agent
        state: started
        enabled: true
      register: k3s_service_start
      when: k3s_check.rc == 0

    - name: Wait for k3s-agent service to be active
      systemd:
        name: k3s-agent
      register: k3s_service_wait
      until: k3s_service_wait.status.ActiveState == 'active'
      retries: 30
      delay: 2
      failed_when: false
      when: k3s_check.rc == 0

    - name: Check k3s-agent logs if service failed to start
      shell: sudo journalctl -u k3s-agent --no-pager -n 10 | tail -10
      register: k3s_logs_check
      changed_when: false
      failed_when: false
      when: k3s_check.rc == 0 and k3s_service_wait.status.ActiveState | default('') != 'active'

    - name: Display k3s-agent logs if service failed
      debug:
        var: k3s_logs_check.stdout_lines
      when: k3s_check.rc == 0 and k3s_service_wait.status.ActiveState | default('') != 'active'

    - name: Wait for k3s to register with cluster
      pause:
        seconds: 10
      when: k3s_install.changed | default(false)

    # =========================================================================
    # Cleanup Diagnostic Files
    # =========================================================================
    - name: Remove Ansible backup files older than 7 days
      shell: |
        find /boot -name "*.bak.ansible-*" -type f -mtime +7 -delete 2>/dev/null || true
        find /boot/firmware -name "*.bak.ansible-*" -type f -mtime +7 -delete 2>/dev/null || true
        find /etc -name "*.bak.ansible-*" -type f -mtime +7 -delete 2>/dev/null || true
      failed_when: false
      changed_when: false

    # =========================================================================
    # Completion message
    # =========================================================================
    - name: Display completion message
      debug:
        msg:
          - "{{ '✅ k3s worker installation complete!' if not (k3s_already_installed | default(false)) else '✅ k3s worker is already installed and running' }}"
          - ""
          - "Worker node should now be registered with the cluster"
          - "Diagnostic files: Cleaned up"
          - ""
          - "Verify on control plane:"
          - "  export KUBECONFIG=~/.kube/config-eldertree"
          - "  kubectl get nodes"
